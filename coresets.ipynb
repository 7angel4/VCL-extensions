{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3d24504-ddbd-4d0b-b495-45d2e8814bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run constants.ipynb\n",
    "%run dataloaders.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f5df794-fb9b-46b7-9b1e-61e17df75f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoresetAlg:\n",
    "    def __init__(self, coreset_size=200):\n",
    "        self.coresets = []\n",
    "        self.coreset_size = coreset_size\n",
    "\n",
    "    def add_coreset(self, dataloader):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3444c2d-4a85-4c06-bced-13988e567a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCoresetAlg(CoresetAlg):\n",
    "    def __init__(self, coreset_size=200):\n",
    "        super().__init__(coreset_size)\n",
    "\n",
    "    def add_coreset(self, dataloader):\n",
    "        task_indices = dataloader.sampler.indices\n",
    "        shuffled_indices = task_indices[torch.randperm(len(task_indices))]\n",
    "        \n",
    "        # Split into coreset and remaining data\n",
    "        core_indices, remaining_indices = shuffled_indices[:self.coreset_size], shuffled_indices[self.coreset_size:]\n",
    "        dataloader.sampler.indices = remaining_indices\n",
    "        \n",
    "        # Create coreset loader\n",
    "        coreset_loader = DataLoader(\n",
    "            dataloader.dataset,\n",
    "            batch_size=dataloader.batch_size,\n",
    "            sampler=SubsetRandomSampler(core_indices)\n",
    "        )\n",
    "        self.coresets.append(coreset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d89a9d5d-6454-4297-bdb9-3f8bea3e5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KCenterCoresetAlg(CoresetAlg):\n",
    "    def __init__(self, coreset_size=200):\n",
    "        super().__init__(coreset_size)\n",
    "\n",
    "    def add_coreset(self, dataloader):\n",
    "        \"\"\" Adds a coreset selected by greedy k-center algorithm to the existing set of coresets. \"\"\"\n",
    "        X_train = self._extract_trainset(dataloader)\n",
    "        \n",
    "        # Initialize distances and first point in the coreset\n",
    "        dists = np.full(X_train.shape[0], np.inf)\n",
    "        current_index = 0\n",
    "        dists = self._update_distances(dists, X_train, current_index)\n",
    "        selected_indices = [current_index]\n",
    "    \n",
    "        # Select k-center points\n",
    "        for _ in range(1, self.coreset_size):\n",
    "            current_index = np.argmax(dists)\n",
    "            dists = self._update_distances(dists, X_train, current_index)\n",
    "            selected_indices.append(current_index)\n",
    "\n",
    "        task_indices = dataloader.sampler.indices\n",
    "        core_indices = task_indices[selected_indices]  # selected index in X_train = index into task_indices\n",
    "        remaining_indices = np.setdiff1d(task_indices, core_indices)\n",
    "        coreset_loader = DataLoader(\n",
    "            dataloader.dataset,\n",
    "            batch_size=dataloader.batch_size,\n",
    "            sampler=SubsetRandomSampler(core_indices)\n",
    "        )\n",
    "    \n",
    "        # Update original dataloader's sampler to exclude coreset points\n",
    "        dataloader.sampler.indices = remaining_indices\n",
    "        self.coresets.append(coreset_loader)  # store new coreset\n",
    "    \n",
    "\n",
    "    def _extract_trainset(self, dataloader):\n",
    "        \"\"\"Extract flattened trainset and original indices\"\"\"\n",
    "        task_indices = dataloader.sampler.indices  # only has target classes in this task\n",
    "        X_train = []\n",
    "        for ind in task_indices:\n",
    "            img, _ = dataloader.dataset[ind]\n",
    "            X_train.append(img.view(-1).numpy())        \n",
    "        return np.stack(X_train) \n",
    "    \n",
    "    def _update_distances(self, dists, X, current_id):\n",
    "        \"\"\"Update distances to current center\"\"\"\n",
    "        new_dists = np.linalg.norm(X - X[current_id], axis=1)\n",
    "        return np.minimum(dists, new_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ebe0f9-ccbe-42a1-b321-51213dce3692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
