{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c154c780-ae51-4763-b37c-4fecb3b0b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Exponential, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7e65984b-75c7-419f-8468-a56a6113da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def kl(self):\n",
    "        \"\"\"KL(q,p), where q is Gaussian and p is from the given prior family\"\"\"\n",
    "        pass\n",
    "\n",
    "    def init_params_for(self, model, init_mu=0.0, init_scale=0.1, init_const=-3.0):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ab2f6854-66c0-4bb1-82df-6c86de5de2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPrior(Prior):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def kl(self, q, p):\n",
    "        q_mu, q_sigma = q['mu'], q['scale']\n",
    "        p_mu, p_sigma = p['mu'], p['scale']\n",
    "        \n",
    "        ratio = (q_sigma / p_sigma) ** 2\n",
    "        log_std = torch.log(1./ratio)\n",
    "        mean_term = ratio + ((q_mu - p_mu) / p_sigma) ** 2\n",
    "        return 0.5 * (log_std + mean_term - 1)\n",
    "\n",
    "    # The following matches the VCL authors' code\n",
    "    def init_params_for(self, model, init_mu=0.0, init_scale=0.1, init_const=-3.0):\n",
    "        nn.init.trunc_normal_(model.W_mu, mean=init_mu, std=init_scale)\n",
    "        nn.init.trunc_normal_(model.b_mu, mean=init_mu, std=init_scale)\n",
    "        model.W_rho.data.fill_(init_const)\n",
    "        model.b_rho.data.fill_(init_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a779ecd6-9335-492d-99a5-ed7ad79a41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialPrior(Prior):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    # def kl(self, q, p):\n",
    "    #     q_mu, q_sigma = q['mu'], q['scale']\n",
    "    #     p_mu, p_sigma = p['mu'], p['scale']\n",
    "    #     # E_q[|X|] where q(X) = N(X; mu, sigma^2)\n",
    "    #     coef = torch.tensor(np.sqrt(2.0 / np.pi), dtype=torch.float32, device=DEVICE)\n",
    "    #     E_abs = coef * p_sigma * torch.exp(-p_mu**2 / (2*p_sigma**2)) + \\\n",
    "    #             p_mu * (1. - 2 * Normal(loc=0., scale=1.).cdf(-p_mu/p_sigma))  # approx_scale\n",
    "    #     lambda_hat = 1./E_abs\n",
    "    #     logq = -0.5 * (1. + torch.log(2*np.pi * (q_sigma ** 2)))  # Gaussian entropy\n",
    "    #     return logq + lambda_hat * q_mu - torch.log(lambda_hat)\n",
    "\n",
    "    def kl(self, q, p):\n",
    "        q_mu, q_sigma = q['mu'], q['scale']\n",
    "        p_mu, p_sigma = p['mu'], p['scale']\n",
    "        normcdf = Normal(loc=0., scale=1.).cdf\n",
    "        E_abs = torch.mul(p_sigma, np.sqrt(2./np.pi)) * torch.exp(-p_mu**2 / (2*p_sigma**2)) + \\\n",
    "                p_mu * (1. - 2 * normcdf(-p_mu/p_sigma))\n",
    "        lambda_hat = 1. / E_abs  # estimate for lambda\n",
    "        logp = torch.log(lambda_hat) \\\n",
    "                - torch.div(lambda_hat * q_sigma, np.sqrt(2*np.pi)) * torch.exp(-q_mu**2 / (2*q_sigma**2)) \\\n",
    "                - lambda_hat * q_mu * (1.- normcdf(-q_mu/q_sigma))\n",
    "        logq = -0.5 * (1. + torch.log(2 * np.pi * q_sigma**2))  # Gaussian entropy\n",
    "        return logq - logp\n",
    "    \n",
    "\n",
    "    def init_params_for(self, model, init_mu=0.0, init_scale=0.1, init_const=-3.0):\n",
    "        exp_dist = Exponential(np.sqrt(np.pi/2) / init_scale)  # Exp(rate)\n",
    "        model.W_mu.data = exp_dist.rsample(model.W_mu.shape) * torch.sign(torch.randn_like(model.W_mu))  # we still allow negative weights (see section C.1 of our paper)\n",
    "        model.b_mu.data = exp_dist.rsample(model.b_mu.shape) * torch.sign(torch.randn_like(model.b_mu))\n",
    "        model.W_rho.data.fill_(init_const) # to match the VCL authors' initialisation in code\n",
    "        model.b_rho.data.fill_(init_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3b8fc-7eb3-4ca0-98b1-658cd00fee34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c4a92-1051-4ca4-992a-fa93a93899b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e627a-87de-4e0d-aaf0-37a8d7571a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
