{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2cfbb9-47a0-432e-b0f8-c7d02239b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run constants.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846cf3c6-4f59-48ab-98ac-d7b568e21062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentConfig:\n",
    "    def __init__(self, \n",
    "                 dataset_type='split',\n",
    "                 task_type='classification',\n",
    "                 prior_type='gaussian',\n",
    "                 init_prior_mu=0.0,\n",
    "                 init_prior_scale=0.1,\n",
    "                 init_const=-6.0,\n",
    "                 coreset_alg_name=\"random\",\n",
    "                 coreset_size=200\n",
    "                ):\n",
    "        # Model hyperparameters\n",
    "        self.prior_type = prior_type  # 'gaussian' or 'exponential'\n",
    "        self.task_type = task_type\n",
    "        self.dataset_type = dataset_type\n",
    "        self.init_prior_mu = init_prior_mu\n",
    "        self.init_prior_scale = init_prior_scale\n",
    "        self.init_const = init_const\n",
    "        self.input_dim = 784\n",
    "        self.hidden_dim = 256\n",
    "        self.num_samples = 10\n",
    "        self.split_tasks = [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n",
    "        self.update_prior = True\n",
    "        \n",
    "        # Training parameters\n",
    "        self.num_epochs = 100\n",
    "        self.batch_size = 256\n",
    "        self.learning_rate = 0.001\n",
    "        self.coreset_alg_name = coreset_alg_name\n",
    "        self.coreset_size = coreset_size\n",
    "        self.patience = 5\n",
    "        self.early_stop_threshold = 1e-4\n",
    "        \n",
    "        \n",
    "    def validate(self):\n",
    "        assert self.prior_type in ['gaussian', 'exponential']\n",
    "        assert self.dataset_type in ['split', 'permuted']\n",
    "        assert len(self.tasks) > 0\n",
    "\n",
    "    @property\n",
    "    def coreset_alg(self):\n",
    "        \"\"\"Get coreset algorithm as a function based on the config\"\"\"\n",
    "        if self.coreset_alg_name == \"kcenter\":\n",
    "            return KCenterCoresetAlg(self.coreset_size)\n",
    "        elif self.coreset_alg_name == \"random\":\n",
    "            return RandomCoresetAlg(self.coreset_size)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def tasks(self):\n",
    "        return range(NUM_MNIST_CLASSES) if self.dataset_type == 'permuted' else self.split_tasks\n",
    "\n",
    "    @property\n",
    "    def dataloaders(self):\n",
    "        dataloaders = PermutedDataLoader(self.tasks, batch_size=self.batch_size) if self.dataset_type == 'permuted' else \\\n",
    "                        SplitDataLoader(self.tasks, batch_size=self.batch_size)\n",
    "        return dataloaders.run()\n",
    "\n",
    "    @property\n",
    "    def output_dims(self):\n",
    "        # Multihead NN for SplitMNIST\n",
    "        if self.dataset_type == 'split' and self.task_type == 'classification':\n",
    "            return [len(t) for t in self.tasks]\n",
    "        elif self.dataset_type == 'split' and self.task_type == 'regression':\n",
    "            return [NUM_MNIST_CLASSES for _ in self.tasks]  # one-hot-encoding of classes will have size NUM_MNIST_CLASSES\n",
    "        else:\n",
    "            return [NUM_MNIST_CLASSES] # single head for PermutedMNIST\n",
    "\n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        return self.output_dims[0]\n",
    "\n",
    "    @property\n",
    "    def eval_metric(self):\n",
    "        return 'Accuracy' if self.task_type == 'classification' else 'RMSE'\n",
    "\n",
    "    @property\n",
    "    def prior(self):\n",
    "        return ExponentialPrior() if self.prior_type == 'exponential' else GaussianPrior()\n",
    "\n",
    "    def prepare_targets(self, targets, task_id):\n",
    "        task = self.tasks[task_id]\n",
    "        if self.dataset_type == 'split' and self.task_type == 'classification':\n",
    "            # targets -= task[0] \n",
    "            # always treat SplitMNIST tasks as binary classification with class 0/1\n",
    "            # so we map the first digit to class 0, second digit to class 1\n",
    "            task_mapping = {task[0]: 0, task[1]: 1}\n",
    "            targets = torch.tensor([task_mapping[t.item()] for t in targets], device=DEVICE)\n",
    "        elif self.task_type == 'regression':\n",
    "            # one hot encoding of class labels\n",
    "            targets = F.one_hot(targets, num_classes=self.output_dim).float()  # [batch_size, 10]\n",
    "        return targets\n",
    "\n",
    "    def loss_fn(self, outputs, targets, task_id):\n",
    "        # targets are not yet processed\n",
    "        # print('loss_fn outputs:', outputs)\n",
    "        # print('loss_fn targets:', targets)  # should still contain original class labels\n",
    "        final_targets = self.prepare_targets(targets, task_id)\n",
    "        if self.task_type == 'regression': # Gaussian likelihood - MSE loss\n",
    "            loss = F.mse_loss(outputs.mean(-1), final_targets)\n",
    "        else: # Categorical likelihood - negative log likelihood loss\n",
    "            # print('loss_fn final targets:', final_targets)  # should still contain original class labels\n",
    "            log_output = torch.logsumexp(outputs, dim=-1) - np.log(self.num_samples)\n",
    "            loss = F.nll_loss(log_output, final_targets)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, outputs, targets, task_id):\n",
    "        targets = self.prepare_targets(targets, task_id)\n",
    "        # Calculate metric based on task type\n",
    "        if self.task_type == 'regression':\n",
    "            pred = outputs.mean(-1)\n",
    "            rmse = torch.sqrt(F.mse_loss(pred, targets))\n",
    "            return rmse.item()\n",
    "        else:\n",
    "            log_output = torch.logsumexp(outputs, dim=-1) - np.log(self.num_samples)\n",
    "            acc = (log_output.argmax(-1) == targets).float().mean()\n",
    "            return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423fab8-d132-4af7-a23e-f6a52835777c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb80a0c-7921-40c1-a20b-0d7f1cb7c8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
