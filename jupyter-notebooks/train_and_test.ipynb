{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bdd95d5-4d34-4f82-8c3a-fc9a88808e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run constants.ipynb\n",
    "%run config.ipynb\n",
    "%run models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67831d9-6b14-4ea4-bb8c-f1975aeda763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, task_id):\n",
    "    \"\"\"Train model on a specific task\"\"\"\n",
    "    config = model.config\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    prev_loss = float('inf')\n",
    "    num_consec_worse_epochs = 0\n",
    "    task_id = model.task_id(task_id)\n",
    "    \n",
    "    for epoch in range(config.num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # Monte Carlo sampling\n",
    "            outputs = torch.zeros(inputs.size(0), config.output_dim,   # len(task)\n",
    "                                  config.num_samples, device=DEVICE)\n",
    "            for i in range(config.num_samples):\n",
    "                net_out = model(inputs, task_id)\n",
    "                outputs[..., i] = (net_out if config.task_type == 'regression' else F.log_softmax(net_out, dim=-1))\n",
    "\n",
    "            loss = model.compute_loss(outputs, targets, task_id)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # Early stopping\n",
    "        if epoch_loss + config.early_stop_threshold > prev_loss:\n",
    "            prev_loss = epoch_loss\n",
    "            num_consec_worse_epochs = 0\n",
    "        else:\n",
    "            num_consec_worse_epochs += 1\n",
    "            if num_consec_worse_epochs >= config.patience:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd6a88d-67d6-4073-a915-3f6ee548ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, task_id, ret_std=False):\n",
    "    \"\"\"Test model supporting both classification and regression\"\"\"\n",
    "    model.eval()\n",
    "    metrics = []\n",
    "    config = model.config  # for brevity\n",
    "    task_id = model.task_id(task_id)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            \n",
    "            outputs = torch.zeros(inputs.size(0), config.output_dim,\n",
    "                                config.num_samples, device=DEVICE)\n",
    "            for i in range(config.num_samples):\n",
    "                net_out = model(inputs, task_id)\n",
    "                outputs[..., i] = (net_out if config.task_type == 'regression' else F.log_softmax(net_out, dim=-1))\n",
    "            \n",
    "            # Calculate metric based on task type\n",
    "            metrics.append(config.evaluate(outputs, targets, task_id))\n",
    "    \n",
    "    return np.mean(metrics) if not ret_std else (np.mean(metrics), np.std(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14fe95-5557-4ed5-95f8-2254892b9135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
